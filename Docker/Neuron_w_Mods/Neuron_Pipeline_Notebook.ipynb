{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "# Basic libraries for data manipulation\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "\n",
    "# Neuron libraries\n",
    "from neuron import h\n",
    "from neuron import load_mechanisms\n",
    "import neuron\n",
    "\n",
    "import ipywidgets as wdg\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "#Load main NEURON modules\n",
    "load_mechanisms('/work/nrn-7.4/x86_64/bin/')\n",
    "h.load_file('stdrun.hoc')\n",
    "h('objref nil')\n",
    "\n",
    "class BallAndStick(object):\n",
    "    \n",
    "    def __init__(self, E_PAS = -75.0, Rm = 10000.0, Cm = 1.0, Ra = 150.0, celsius = 23, dend_nseg = 11, \n",
    "                 soma_diam = 25, dend_length = 25, dend_diam = 1):\n",
    "         # Initialise ephys parameters\n",
    "        self.E_PAS = E_PAS\n",
    "        self.Rm = Rm\n",
    "        self.Cm = Cm\n",
    "        self.Ra = Ra\n",
    "        self.CELSIUS = celsius\n",
    "        \n",
    "        # Create soma and dendrite and connect them together\n",
    "        self.soma = h.Section(name=\"soma\")\n",
    "        self.dend = h.Section(name=\"dend\")\n",
    "        self.dend.connect(self.soma(1))\n",
    "        \n",
    "        # Initialise soma and dendrite diameters\n",
    "        self.dend.L = dend_length # This makes soma 500 microns squared\n",
    "        self.soma.diam = soma_diam\n",
    "        self.dend.diam = dend_diam\n",
    "        self.soma.L = soma_diam\n",
    "        \n",
    "        # Set dendritic segments\n",
    "        self.dend.nseg = dend_nseg\n",
    "        \n",
    "        # Insert conductances\n",
    "        self.soma = self.add_conductances(self.soma)\n",
    "        self.dend = self.add_conductances(self.dend)\n",
    "        \n",
    "        # Define variables to be overwritten\n",
    "        self.activation_pattern = []\n",
    "        self.AMPA_ncs = []\n",
    "        \n",
    "        # Insert tapering of dendrite\n",
    "#         self.dend = self.taper_diam(self.dend,2,1)\n",
    "    \n",
    "    def taper_diam(self, sec,zero_bound,one_bound):\n",
    "        for (num_sec, d) in zip(sec, np.linspace(zero_bound, one_bound, sec.nseg)):\n",
    "            num_sec.diam=d\n",
    "            \n",
    "        return sec\n",
    "\n",
    "    def add_conductances(self, nrn_sec):\n",
    "        nrn_sec.insert('pas')\n",
    "        nrn_sec.Ra = self.Ra\n",
    "        nrn_sec.e_pas = self.E_PAS\n",
    "        nrn_sec.g_pas = 1.0/self.Rm\n",
    "        for seg in nrn_sec:\n",
    "            seg.cm = self.Cm\n",
    "      \n",
    "        return nrn_sec\n",
    "    \n",
    "    def add_AMPA(self, func = h.Exp2Syn, section = h.Section(), locs = [0.5], gmax = 0.5, tau1 = 0.1, tau2 = 1 ):\n",
    "        self.AMPA_syns, self.AMPA_ncs = [], []\n",
    "        for syn_no in range(len(locs)):\n",
    "            SYN = func(float(locs[syn_no]), sec = section)\n",
    "            SYN.tau1 = tau1\n",
    "            SYN.tau2 = tau2\n",
    "            if type(gmax) == list or type(gmax) == np.ndarray:\n",
    "                NC = h.NetCon(h.nil, SYN, 0, 0, gmax[syn_no])\n",
    "            else:\n",
    "                NC = h.NetCon(h.nil, SYN, 0, 0, gmax)\n",
    "                \n",
    "            self.AMPA_syns.append(SYN), self.AMPA_ncs.append(NC)\n",
    "            \n",
    "    def add_NMDA(self,locs=[0.5],gmax=[1],rel = [20]):\n",
    "        self.NMDAlist = []\n",
    "        self.preNMDA_list = []\n",
    "        for loc in enumerate(locs):\n",
    "            PRE = h.Section()\n",
    "            PRE.diam = 1.0 ; PRE.L=1.0\n",
    "            PRE.insert('rel')\n",
    "            PRE.dur_rel = 0.5\n",
    "            PRE.amp_rel = 2.0\n",
    "            PRE.del_rel = rel[loc[0]]\n",
    "            NMDA = h.NMDA_Mg_T(self.dend(loc[1]))\n",
    "            NMDA.gmax = gmax[loc[0]]\n",
    "            h.setpointer(PRE(0.5).rel._ref_T,'C',NMDA)\n",
    "            self.preNMDA_list.append(PRE)\n",
    "            self.NMDAlist.append(NMDA)\n",
    "            \n",
    "    def simulate(self, v_init = -75, t_stop=200, NMDA=False):\n",
    "        \"\"\" Run the main simulation. Accepts AMPA only or with NMDA depending on passing of the NMDA parameters.\n",
    "        Records from soma.\"\"\"\n",
    "        \n",
    "        self.vec = {}\n",
    "        for type_rec in \"vrec\",\"trec\":\n",
    "            self.vec[type_rec] = h.Vector()\n",
    "\n",
    "        self.vec[\"trec\"].record(h._ref_t)\n",
    "        self.vec[\"vrec\"].record(self.soma(0.5)._ref_v)\n",
    "        \n",
    "        if NMDA==True:\n",
    "            self.NMDAgrec, self.NMDAirec = [], []\n",
    "            for chan in np.arange(0, len(self.NMDAlist)):\n",
    "                loc = self.NMDAlist[chan].get_loc()\n",
    "                h.pop_section()\n",
    "                self.NMDAgrec.append(h.Vector())\n",
    "                self.NMDAgrec[chan].record(self.NMDAlist[chan]._ref_g)\n",
    "                self.NMDAirec.append(h.Vector())\n",
    "                self.NMDAirec[chan].record(self.NMDAlist[chan]._ref_i)\n",
    "        \n",
    "        h.celsius = self.CELSIUS\n",
    "        h.finitialize(v_init)\n",
    "        neuron.run(t_stop)\n",
    "        \n",
    "    def netcon_events(self):\n",
    "        for syn_event in self.activation_pattern:\n",
    "            self.AMPA_ncs[syn_event[0]].event(float(syn_event[1]))   \n",
    "        \n",
    "    def run_IN_OUT(self, base_AMPA = 0.0005, base_NMDA = 8000, synapses = 16, base_step = 2, \n",
    "                   nmda_gradient_top = 1, nmda_gradient_bot = 1, ampa_gradient_top = 1, ampa_gradient_bot = 1,\n",
    "                   IN_scale_ampa = 1, IN_scale_nmda = 1, OUT_scale_ampa = 1, OUT_scale_nmda = 1,\n",
    "                   syn_placement_bot = 0, syn_placement_top = 1, dendrite = 13, base_time = 20):\n",
    "        \n",
    "        # First reconstruct parameters\n",
    "        syn_placement = np.linspace(syn_placement_bot,syn_placement_top,synapses)\n",
    "                    \n",
    "        for seq_type in [\"IN\",\"OUT\"]:\n",
    "\n",
    "            # Define synapse placement for IN and OUT sequences\n",
    "            if seq_type == \"IN\":\n",
    "                syn_sequence = np.linspace(base_time,base_time+synapses*base_step,synapses)[::-1]\n",
    "            if seq_type == \"OUT\":\n",
    "                syn_sequence = np.linspace(base_time,base_time+synapses*base_step,synapses)\n",
    "\n",
    "            self.activation_pattern = enumerate(syn_sequence)\n",
    "            \n",
    "            ampa_gradient = np.linspace(1,1,synapses)\n",
    "            nmda_gradient = np.linspace(1,1,synapses)\n",
    "            \n",
    "            # Scale synapses \n",
    "            ampa_gmax = base_AMPA*ampa_gradient*IN_scale_ampa\n",
    "            nmda_gmax = base_NMDA*nmda_gradient*IN_scale_nmda\n",
    "\n",
    "            #Add synapses\n",
    "            self.add_AMPA(locs=syn_placement,gmax=ampa_gmax,tau1=0.1,tau2=1, section =self.dend)\n",
    "            self.add_NMDA(locs=syn_placement,gmax=nmda_gmax,rel=syn_sequence)\n",
    "\n",
    "            # Run the simulation and plot\n",
    "            fih = h.FInitializeHandler(1,self.netcon_events)\n",
    "            self.simulate(t_stop=500,NMDA=True)\n",
    "\n",
    "            if seq_type == \"IN\":\n",
    "                IN = np.array(self.vec[\"vrec\"])\n",
    "\n",
    "            if seq_type == \"OUT\":\n",
    "                OUT = np.array(self.vec[\"vrec\"])\n",
    "                \n",
    "        return IN,OUT\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 4/13 [00:06<00:15,  1.72s/it]"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "class Simulator(object):\n",
    "    \n",
    "    def __init__(self, simulation_params):\n",
    "        \n",
    "        # Initialise parameters\n",
    "        self.basal_params =  {\"E_PAS\":-75.0, \"Rm\":10000.0, \"Cm\": 1.0, \"Ra\":150.0, \"celsius\":23, \"dend_nseg\":11}\n",
    "        self.simulation_params = simulation_params\n",
    "        \n",
    "        # Identify variables that need to be passed to different functions\n",
    "        self.model_vars = [\"dend_length\",\"dend_diam\"]\n",
    "        self.model_runs = [\"base_AMPA\",\"base_NMDA\",\"synapses\",\"base_step\"]\n",
    "        \n",
    "        self._get_combinations()\n",
    "        \n",
    "    def _get_combinations(self):\n",
    "        \n",
    "        allNames = sorted(self.simulation_params)\n",
    "        combinations = itertools.product(*(self.simulation_params[Name] for Name in allNames))\n",
    "        self.combinations = pd.DataFrame(list(combinations), columns = allNames)\n",
    "    \n",
    "    def _run_simulation(self,array):\n",
    "        # Get iterative variables\n",
    "        model_sims = array[self.model_vars].to_dict(orient=\"records\")\n",
    "        model_runs = array[self.model_runs].to_dict(orient=\"records\")\n",
    "                \n",
    "        rows = []\n",
    "        for count in tqdm(range(array.shape[0])):\n",
    "            model = BallAndStick(**model_sims[count])\n",
    "            \n",
    "            IN, OUT = model.run_IN_OUT(**model_runs[count])\n",
    "            \n",
    "            temp = array.iloc[count].to_dict()\n",
    "            temp[\"IN\"] = np.max(IN)\n",
    "            temp[\"OUT\"] = np.max(OUT)\n",
    "            rows.append(temp)\n",
    "            \n",
    "        return rows\n",
    "            \n",
    "    def runner(self, processes = 4):\n",
    "\n",
    "        arrays = np.array_split(self.combinations, processes)\n",
    "        with mp.Pool(processes = processes) as pool:\n",
    "            self.data = pool.map(self._run_simulation,arrays)\n",
    "            self.data = pd.concat([pd.DataFrame(i) for i in self.data])\n",
    "            \n",
    "        \n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "    \n",
    "simulation_params = {\"base_AMPA\": np.linspace(0.0001,0.0015,20), \"base_NMDA\": np.linspace(1000,16000,20), \n",
    "                     \"synapses\":list(np.arange(8,26).astype(int)), \"dend_length\":[25,50,75,100,200], \n",
    "                     \"dend_diam\":[0.5, 1, 2],\"base_step\":[0.1,1,2,4,8,10]}\n",
    "\n",
    "sim = Simulator(simulation_params)\n",
    "sim.runner(processes = 4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IN</th>\n",
       "      <th>OUT</th>\n",
       "      <th>base_AMPA</th>\n",
       "      <th>base_NMDA</th>\n",
       "      <th>dend_diam</th>\n",
       "      <th>dend_length</th>\n",
       "      <th>synapses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-72.570328</td>\n",
       "      <td>-72.583587</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-72.321756</td>\n",
       "      <td>-72.337289</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-72.079001</td>\n",
       "      <td>-72.096763</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-71.843220</td>\n",
       "      <td>-71.862592</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-71.610235</td>\n",
       "      <td>-71.632971</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          IN        OUT  base_AMPA  base_NMDA  dend_diam  dend_length  \\\n",
       "0 -72.570328 -72.583587     0.0001     1000.0        0.5         25.0   \n",
       "1 -72.321756 -72.337289     0.0001     1000.0        0.5         25.0   \n",
       "2 -72.079001 -72.096763     0.0001     1000.0        0.5         25.0   \n",
       "3 -71.843220 -71.862592     0.0001     1000.0        0.5         25.0   \n",
       "4 -71.610235 -71.632971     0.0001     1000.0        0.5         25.0   \n",
       "\n",
       "   synapses  \n",
       "0       8.0  \n",
       "1       9.0  \n",
       "2      10.0  \n",
       "3      11.0  \n",
       "4      12.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incomplete - Work in progress !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/matplotlib/__init__.py:942: MatplotlibDeprecationWarning: nbagg.transparent is deprecated and ignored. Use figure.facecolor instead.\n",
      "  mplDeprecation)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5cdb32f5e14a9cac6daf8b8822438e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1918it [02:45, 11.56it/s]"
     ]
    }
   ],
   "source": [
    "class BS_heatmap:\n",
    "    def __init__(self, file_path, base_step = 8.0, dend_length = 50.0, soma_diam=50.0,dend_diam = 1,split_analysis = False, \n",
    "                 min_epsp_threshold=0.2, max_epsp_threshold=0.5):\n",
    "        self.xdata = []\n",
    "        self.ydata = []\n",
    "        self.current_point = [] # Variable to store selected point on a graph\n",
    "        self.hm_ranges = {}\n",
    "        self.cbar = []\n",
    "        \n",
    "        self.dend_length = dend_length\n",
    "        self.soma_diam = soma_diam\n",
    "        \n",
    "        # Set thresholds\n",
    "        self.min_epsp_threshold, self.max_epsp_threshold = min_epsp_threshold, max_epsp_threshold\n",
    "        \n",
    "        # Initialise data and other figures\n",
    "        self.df = pd.read_csv(file_path)\n",
    "        self.fig, (self.ax_heat, self.ax_line) = plt.subplots(nrows=1,ncols=2)\n",
    "        \n",
    "        self.heatmap_plot(base_step = base_step,dend_length=dend_length,soma_diam=soma_diam,\n",
    "                          split_analysis = split_analysis)\n",
    "\n",
    "        self.cid = self.fig.canvas.mpl_connect(\"button_press_event\",self)\n",
    "\n",
    "        \n",
    "    def __call__(self,event):\n",
    "        # Initialise first point or update if first point has been plotted\n",
    "        if self.current_point != []:\n",
    "            self.current_point[0].set_xdata(event.xdata)\n",
    "            self.current_point[0].set_ydata(event.ydata)\n",
    "        else:\n",
    "            self.current_point = self.ax_heat.plot(event.xdata,event.ydata,\"mo\",ms=5,mec=\"none\")\n",
    "          \n",
    "        ampa = ((self.hm_ranges[\"ampa\"][1]-self.hm_ranges[\"ampa\"][0])/50)*event.ydata+self.hm_ranges[\"ampa\"][0]\n",
    "        nmda = ((self.hm_ranges[\"nmda\"][1]-self.hm_ranges[\"nmda\"][0])/50)*event.xdata+self.hm_ranges[\"nmda\"][0]\n",
    "        \n",
    "        self.ax_line.cla()        \n",
    "        \n",
    "        # Setup variables\n",
    "        MODEL.dend.L = self.dend_length\n",
    "        MODEL.soma.diam = self.soma_diam\n",
    "        MODEL.soma.L = self.soma_diam\n",
    "        IN, OUT = MODEL.run_IN_OUT(base_AMPA=ampa, base_NMDA=nmda, base_step=self.base_step)\n",
    "        print(\"Soma L:\",MODEL.soma.L, \"Soma diam:\",MODEL.soma.diam,\"MODEL.dend.L\",MODEL.dend.L,\"MODEL.dend.diam:\",\n",
    "             MODEL.dend.diam)\n",
    "        \n",
    "        # Show on plot        \n",
    "        self.ax_line.plot(IN, \"r\")\n",
    "        self.ax_line.plot(OUT, \"b\")\n",
    "        \n",
    "    def heatmap_plot(self, base_step = 8.0, dend_length = 50.0, soma_diam = 50.0,split_analysis = False):\n",
    "        \n",
    "        self.hm_data = self.df[(self.df[\"base_step\"] == float(base_step)) & (self.df[\"length\"] == float(dend_length)) \n",
    "                               & (self.df[\"soma_diam\"] == float(soma_diam))]\n",
    "        \n",
    "        #### No dend diam in passed arguments!!!!!!\n",
    "        \n",
    "        # Set global variables\n",
    "        self.base_step, self.length, self.soma_diam = base_step, dend_length, soma_diam\n",
    "        \n",
    "        self.cbar = self.ax_heat.imshow(self.hm_data[\"diff\"].values.reshape(50,50))\n",
    "        self.fig.colorbar(self.cbar)\n",
    "        \n",
    "        # Find the current ranges of the plot\n",
    "        self.hm_ranges[\"ampa\"] = (self.df[\"ampa\"].min(), self.df[\"ampa\"].max())\n",
    "        self.hm_ranges[\"nmda\"] = (self.df[\"nmda\"].min(), self.df[\"nmda\"].max())\n",
    "        \n",
    "        # Add appropriate ranges to the plot\n",
    "        self.ax_heat.set_xticks([0,50]),self.ax_heat.set_yticks([0,50])\n",
    "        self.ax_heat.set_xticklabels(self.hm_ranges[\"nmda\"]), self.ax_heat.set_yticklabels(self.hm_ranges[\"ampa\"])\n",
    "        \n",
    "        if split_analysis:\n",
    "            self.parallel_run_accepted()\n",
    "            masked_data = self.accepted_vector.reshape(50,50)\n",
    "            masked_data = np.ma.masked_where(masked_data > 0.9, masked_data)\n",
    "            self.ax_heat.imshow(masked_data, alpha = 0.7)\n",
    "            \n",
    "        self.fig.canvas.draw() \n",
    "    \n",
    "    def __run_split_analysis__(self,splitted_df,potentiation_params={\"min\":2.0, \"max\":25.0}):\n",
    "        accepted_df = []\n",
    "        for row in tqdm(splitted_df.iterrows()):\n",
    "            \n",
    "            # Get simulations\n",
    "            epsp = np.max(MODEL.run_IN_OUT(base_AMPA=row[1][\"ampa\"], base_NMDA=row[1][\"nmda\"],synapses=1)) + 75\n",
    "            \n",
    "            # Test if epsp mini is within accepted min and max parameters\n",
    "            test_epsp = not (epsp < self.min_epsp_threshold) | (epsp > self.max_epsp_threshold)\n",
    "            \n",
    "            # Add all the parameters to the data frame\n",
    "            accepted_df.append([row[1][\"ampa\"],row[1][\"nmda\"],epsp,test_epsp,\n",
    "                                MODEL.dend.L, MODEL.soma.L,MODEL.dend.diam, MODEL.soma.diam,\n",
    "                                row[1][\"IN\"],row[1][\"OUT\"]])\n",
    "            \n",
    "        df = pd.DataFrame(accepted_df, columns = [\"ampa\",\"nmda\",\"epsp\",\"mini_threshold\",\n",
    "                                                    \"dend_length\",\"soma_length\",\"dend_diam\",\"soma_diam\",\"IN\",\"OUT\"])\n",
    "        \n",
    "        # Create accepted vector for all tested conditions\n",
    "        df[\"threshold\"] = df[\"mini_threshold\"] \n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def parallel_run_accepted(self):\n",
    "        \"\"\" Create a masked array to overlay for discovered heatmap to show appropriate EPSP values.\"\"\"\n",
    "        \n",
    "        cores = mp.cpu_count()\n",
    "        pool = mp.Pool(processes=cores)\n",
    "        self.accepted_df = pd.concat(pool.map(self.__run_split_analysis__,np.array_split(self.hm_data,cores)))\n",
    "        self.accepted_vector = self.accepted_df[\"threshold\"]\n",
    "        \n",
    "        pool.close()\n",
    "        \n",
    "def netcon_events():\n",
    "    \"\"\" Launch AMPA synapses with netcon events. \"\"\"\n",
    "    for syn_event in MODEL.activation_pattern:\n",
    "        MODEL.AMPA_ncs[syn_event[0]].event(float(syn_event[1]))\n",
    "\n",
    "MODEL = BallAndStick(dend_length=100, soma_diam=50, dend_diam=1)\n",
    "bs_hm = BS_heatmap(\"/shared/simulation_results_v2.csv\", base_step = 2.0, dend_length = 100, split_analysis=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example of multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_split_analysis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0d11cf2f85c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0maccepted_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_split_analysis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs_hm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhm_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0maccepted_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maccepted_vector\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run_split_analysis' is not defined"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def __run_split_analysis__(self,splitted_df):\n",
    "    accepted_vector = []\n",
    "    for row in tqdm(splitted_df.iterrows()):\n",
    "        epsp = np.max(bs.run_IN_OUT(base_AMPA=row[1][\"ampa\"], base_NMDA=row[1][\"nmda\"], synapses = 1)) + 75\n",
    "        if (epsp < min_epsp_threshold) | (epsp > max_epsp_threshold):\n",
    "            accepted_vector.append(False)\n",
    "        else:\n",
    "            accepted_vector.append(True)\n",
    "\n",
    "    return accepted_vector\n",
    "\n",
    "\n",
    "min_epsp_threshold, max_epsp_threshold = 0.2, 0.5\n",
    "\n",
    "cores = mp.cpu_count()\n",
    "pool = mp.Pool(processes=cores)\n",
    "\n",
    "accepted_vector = pool.map(run_split_analysis,np.array_split(bs_hm.hm_data,cores))\n",
    "accepted_vector = [item for sublist in accepted_vector for item in sublist]\n",
    "\n",
    "pool.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "img=imread('/vagrant/parrot.jpg')\n",
    "imgplot = ax.imshow(resize(img, (50,50)))\n",
    "\n",
    "masked_data = bs_hm.accepted_vector.reshape(50,50)\n",
    "masked_data = np.ma.masked_where(masked_data < 0.9, masked_data)\n",
    "ax.imshow(masked_data, alpha = 0.7)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
